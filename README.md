# Toxic message classifier

In this project a multi-headed model is built thatâ€™s capable of detecting different types of toxicity like:
1.	Threats, 
2.	Obscenity
3.	Insults
4.	Identity-based hate
5.	Toxic 
6.	Severe toxic 

## Usage
```
1) Open jupyter notebook file "Toxic Comments Classifier.ipynb"
2) Execute all cells.
3) Go to "/Flask app for toxic comments"
4) Run "toxic_app.py" by wrtiting python toxic_app.py in terminal.
``` 
